<details>
<summary> 

> ### 두가지 모델 비교 

- **Sequential 모델:**
    - Keras라는 딥러닝 라이브러리에서 제공하는 API로, 간단하고 순차적인 딥러닝 모델을 만들 수 있게 해준다.
    - 레이어를 순차적으로 쌓아 구성하고, <u>각 레이어는 이전 레이어의 출력을 입력으로 받아</u> 처리한다.
    - <u><i>단순하고 직관적인 설계</i></u>를 위해 주로 사용되며, 비교적 작은 규모의 모델에 적합하다. 

<br>

- **VGG16 모델:**
    - 옥스퍼드 대학에서 개발한 딥러닝 아키텍처로, 이미지 인식 대회인 ImageNet Challenge에서 우수한 성능을 보여준 모델
    - 16개의 레이어로 구성된 깊은 신경망으로 합성곱(Convolution)과 풀링(Pooling) 레이어로 구성되어 있으며, 마지막에는 완전 연결층(Fully Connected Layer)으로 이어진다.
    - VGG16은 작은 필터 크기(3x3)를 사용하여 깊은 네트워크를 구성하고, 많은 필터(총 16개의 레이어에서 13개의 합성곱 레이어)를 사용하여 다양한 이미지 특징을 추출한다.
    - VGG16은 ImageNet 데이터셋으로 사전 훈련된 가중치를 제공하므로, 전이 학습(Transfer Learning)에 많이 사용된다.

<br><br>

## 🌟 데이터 Augmentation

```python
# 트레이닝 데이터의 제너레이터 설정
train_image_generator = ImageDataGenerator(rescale=1./255,
                                           rotation_range=15,
                                           zoom_range=0.2,
                                           horizontal_flip=True,
                                           )
```
1. `rescale`: 이미지의 픽셀 값을 0과 1 사이로 조정하여 모델의 성능을 개선하고 학습 속도를 향상시키는 데 도움을 줄 수 있다.
2. `rotation_range`: 지정된 각도 범위 내에서 이미지를 -15도부터 +15도까지 무작위로 회전시키기
3. `zoom_range`: 이미지를 0.8배에서 1.2배까지 무작위로 확대/축소하여 다양한 크기와 해상도의 이미지를 처리할 수 있도록 한다. 
4. `horizontal_flip`: 50%의 확률로 이미지를 수평으로 뒤집어 좌우 대칭성을 고려할 수 있도록 한다.

<br>
    
# 최종 모델

> 💡 Training Value
>- loss: 훈련 손실 값
현재 배치에서 모델이 예측한 출력과 실제 레이블 사이의 차이 → `모델의 적합성`
>- accuracy: 훈련 정확도
>현재 배치에서 모델이 올바르게 분류한 샘플의 비율 → `모델의 성능`
>- val_loss: 검증 손실 값 
검증 데이터셋에서 모델의 예측과 실제 레이블 사이의 차이 → `일반화 성능`
>- val_accuracy: 검증 정확도
검증 데이터셋에서 모델이 올바르게 분류한 샘플의 비율 → `일반화 성능`
>- lr: 학습률(learning rate)
모델이 가중치를 업데이트하는 속도를 조절하는 하이퍼파라미터

### 선정성: 노출/비노출 분류
| ![손실값](./img/노출/노출loss.png) | ![정확도](./img/노출/노출accur.png) |
|:---:|:---:|
| 손실값 | 정확도 |

<br>

### 선정성: 관계/비관계 분류 
| ![손실값](./img/관계/관계loss.png) | ![정확도](./img/관계/관계accur.png) |
|:---:|:---:|
| 손실값 | 정확도 |


<br>

### 폭력성: 폭력/비폭력 분류
| ![손실값](./img/폭력/폭력loss.png) | ![정확도](./img/폭력/폭력accur.png) |
|:---:|:---:|
| 손실값 | 정확도 |

